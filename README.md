# Восстановление битых данных стратосферных зондов (Probe Data Recovery)

## Введение

Этот проект является частью более крупного программно-аппаратного комплекса, предназначенного для мониторинга частиц высоких энергий в стратосфере. Комплекс включает наземную станцию, стратосферный зонд (ArcticZond) и космический спутник (ArcticSat-1) для изучения проницаемости атмосферы.

Данный репозиторий фокусируется на **интеллектуальной системе восстановления поврежденных телеметрических сообщений**, поступающих со стратосферного зонда.

## Проблема

Во время полета стратосферного зонда на высоты до 30 км, передача данных по радиоканалу подвержена значительным помехам. Это приводит к различным типам повреждений телеметрических сообщений (передаваемых в формате JSON):

*   **Потеря частей сообщения:** Обрыв начала, конца или середины строки.
*   **Искажение символов:** Шумы и ошибки модуляции могут заменять символы (например, цифру на букву).
*   **Ошибки декодирования:** Передача битых байтов, которые не могут быть декодированы в UTF-8 (часто отображаются как `�`).
*   **Нарушение структуры JSON:** Сообщение перестает быть валидным JSON из-за вышеуказанных проблем.

**Последствия:** Поврежденные сообщения не могут быть автоматически обработаны, что приводит к ошибкам в системах визуализации (карты, графики) и, самое главное, к **потере ценных научных данных**.

## Решение: Модель Transformer

Для решения проблемы разработана нейросетевая модель на основе архитектуры **Transformer (Encoder-Decoder)**, способная восстанавливать поврежденные JSON-сообщения в их предполагаемый исходный, валидный вид.

### Ключевые особенности подхода:

*   **Символьная токенизация:** Модель работает на уровне отдельных символов, что позволяет обрабатывать любые типы искажений, включая невалидные символы и структурные ошибки, без привязки к семантике конкретных полей JSON.
*   **Учет контекста:** Для повышения точности восстановления текущего поврежденного сообщения используется информация из предыдущего успешно принятого валидного сообщения. Вход модели формируется как `[предыдущее_сообщение]<sep>[поврежденное_сообщение]`.
*   **Обучение на синтетических данных:** Модель обучается на большом наборе данных, где валидные сообщения искусственно "портятся" для имитации всего спектра реальных повреждений (обрывы, замены, пропуски). Это обеспечивает робастность модели к разнообразным помехам.
*   **Обработка различных сценариев:** Модель способна восстанавливать сообщения даже при сильных повреждениях, включая невозможность десериализации JSON и сбои при UTF-8-декодировании.

## Технологии

*   **Python 3**
*   **PyTorch:** Основной фреймворк для построения и обучения нейронной сети.
*   **Transformer (nn.Transformer):** Архитектура модели Seq2Seq.
*   **JSON:** Формат обрабатываемых данных.
*   **Кастомный символьный токенизатор:** Реализован для подготовки данных для модели.

## Обучение модели

Модель обучалась с использованием скрипта/ноутбука (`trans2-0.ipynb`), который включает:

1.  **Подготовку данных:** Чтение валидных JSON сообщений, генерация синтетических повреждений.
2.  **Токенизацию:** Преобразование символьных строк во входные тензоры с использованием `CharacterTokenizer`.
3.  **Создание датасета и загрузчика:** Формирование пар (вход -> цель) и батчей для обучения.
4.  **Определение модели:** Инициализация `Seq2SeqTransformer` с заданными гиперпараметрами (EMB_SIZE=256, NHEAD=4, NUM_LAYERS=3, FFN_HID_DIM=512, DROPOUT=0.1, MAX_SEQ_LEN=512).
5.  **Цикл обучения:** Обучение в течение 20 эпох с использованием оптимизатора Adam (LR=0.0001) и функции потерь CrossEntropyLoss (с игнорированием PAD-токенов).
6.  **Валидацию:** Оценка модели на отложенной выборке после каждой эпохи.
7.  **Сохранение:** Сохранение лучшей модели (`transformer_repair_model.pth`), словаря (`vocab.json`) и конфигурации токенизатора (`tokenizer_config.json`) на основе минимальной ошибки на валидации.

Графики потерь на обучении и валидации (см. `losses_combined.png`, `losses_separate.png` если они сгенерированы) показывают успешное обучение модели без признаков переобучения.

## Использование (Инференс)

Для восстановления поврежденного сообщения с использованием обученной модели:

1.  **Загрузите необходимые файлы:**
    *   Веса модели: `transformer_repair_model.pth`
    *   Словарь токенизатора: `vocab.json`
    *   Конфигурацию токенизатора: `tokenizer_config.json`
2.  **Инициализируйте модель и токенизатор:**
    ```python
    import torch
    from main import CharacterTokenizer, Seq2SeqTransformer # Предполагается, что классы модели и токенизатора доступны

    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    MODEL_SAVE_PATH = 'transformer_repair_model.pth'
    VOCAB_SAVE_PATH = 'vocab.json'
    TOKENIZER_SAVE_PATH = 'tokenizer_config.json'

    # Загрузка токенизатора
    tokenizer = CharacterTokenizer.load(VOCAB_SAVE_PATH, TOKENIZER_SAVE_PATH)

    # Загрузка параметров и модели
    checkpoint = torch.load(MODEL_SAVE_PATH, map_location=DEVICE)
    model_params = checkpoint['params']
    # Обновите размер словаря на основе загруженного токенизатора
    loaded_vocab_size = len(tokenizer.char2idx)

    model = Seq2SeqTransformer(
        num_encoder_layers=model_params['num_encoder_layers'],
        num_decoder_layers=model_params['num_decoder_layers'],
        emb_size=model_params['emb_size'],
        nhead=model_params['nhead'],
        src_vocab_size=loaded_vocab_size, # Используем размер из токенизатора
        tgt_vocab_size=loaded_vocab_size, # Используем размер из токенизатора
        dim_feedforward=model_params['dim_feedforward'],
        dropout=model_params['dropout'],
        max_seq_len=model_params.get('max_seq_len', 512) # MAX_SEQ_LEN из параметров
    )
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(DEVICE)
    model.eval()
    ```
3.  **Вызовите функцию восстановления:**
    ```python
    from main import reconstruct_message # Импортируйте функцию

    corrupted_message = '{"pc":34,"pres":100814,"t":25.41903,"h":17.37219,"lat":40.52617' # Пример битого сообщения
    last_valid_message = '{"dr":0.05, ... ,"c":152}' # Пример последнего валидного сообщения (контекст)

    reconstructed = reconstruct_message(
        corrupted_msg=corrupted_message,
        last_valid_msg=last_valid_message,
        model=model,
        tokenizer=tokenizer,
        device=DEVICE,
        max_len=model_params.get('max_seq_len', 512)
    )

    print(f"Corrupted:     {corrupted_message}")
    print(f"Reconstructed: {reconstructed}")
    ```

Функция `reconstruct_message` использует *жадное декодирование* (greedy decoding) для генерации восстановленной последовательности и пытается проверить валидность полученного JSON.

## Результаты и Преимущества

*   **Повышение полноты и надежности данных:** Модель позволяет восстанавливать значительную часть поврежденных сообщений, сокращая потери научной информации.
*   **Автоматизация очистки данных:** Устраняет необходимость ручной проверки и фильтрации битых строк.
*   **Устойчивость к помехам:** Система становится более робастной к реальным условиям радиопередачи в стратосфере.
*   **Улучшение визуализации:** Обеспечивает более непрерывное отображение полетных данных в реальном времени в сопутствующем ПО.

## Интеграция

Модуль восстановления предназначен для встраивания в программное обеспечение визуализации и мониторинга полета зонда (реализовано в `main.py` с использованием PySide6, Folium, VTK и др.). ПО принимает телеметрию, проверяет ее валидность и, в случае повреждения, передает данные в модуль восстановления перед их отображением или сохранением.

## Перспективы развития

*   Использование более продвинутых методов декодирования (например, Beam Search) для повышения качества генерации.
*   Расширение набора и реалистичности синтетических повреждений для обучения.
*   Обучение на большем объеме данных.
*   Адаптация модели для восстановления других типов структурированных данных.
